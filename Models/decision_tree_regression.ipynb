{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "zh17BFBe8K-j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmKZfhSt7J6E"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Regression Model\n",
        "\n",
        "# Import necessary libraries for data handling, visualization, and model evaluation\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "!pip install memory_profiler # Install memory profiler to track memory usage\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "from memory_profiler import memory_usage\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error,r2_score,mean_absolute_percentage_error,mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Dataset upload"
      ],
      "metadata": {
        "id": "Zxp8nEi98Iw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Dataset upload\n",
        "upload = files.upload() # Prompt the user to upload the dataset\n",
        "dataset = pd.read_csv('All_Div_BD.csv') # Load dataset into a DataFrame\n",
        "dataset.shape # Print the shape of the dataset\n",
        "dataset.head(5) # Display the first 5 rows for preview"
      ],
      "metadata": {
        "id": "Hay31guy8I8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Exclude nighttime data (hours outside 7 AM - 7 PM)"
      ],
      "metadata": {
        "id": "GHohA4GX8Ehi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Exclude nighttime data (hours outside 7 AM - 7 PM)\n",
        "# Filter rows with hour < 7 or hour > 19\n",
        "before_seven_am = dataset[dataset['hour']<7]\n",
        "after_seven_pm = dataset[dataset['hour']>19]\n",
        "before_seven_am.head(10)\n",
        "after_seven_pm.head(10)\n",
        "dataset = dataset.drop(before_seven_am.index, axis=0) # Drop early morning rows\n",
        "dataset = dataset.drop(after_seven_pm.index, axis=0) # Drop late evening rows"
      ],
      "metadata": {
        "id": "qXiG-NJe8Eyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Correlation matrix visualization"
      ],
      "metadata": {
        "id": "N8AlGGWl7_yJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Correlation matrix visualization\n",
        "# Analyze correlations between features\n",
        "dataset.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(dataset.corr(), annot=True)"
      ],
      "metadata": {
        "id": "zc8aXqMj8ACi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define dependent (target) and independent (features) variables"
      ],
      "metadata": {
        "id": "O_LguWiD7785"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define dependent (target) and independent (features) variables\n",
        "# Exclude irrelevant columns from the feature set\n",
        "x = dataset.drop(['year','month','day','hour','wbgt'],axis=1)\n",
        "print(x.shape) # Print the shape of the independent variables\n",
        "colms = x.shape[1] # Extract the number of features (columns) in the independent variables\n",
        "colms # Output the number of features\n",
        "y = dataset['wbgt'] # Target variable: WBGT\n",
        "y.shape # Print the shape of the dependent variable"
      ],
      "metadata": {
        "id": "3NIhp_7H78K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train, test, and validation split"
      ],
      "metadata": {
        "id": "3-J24DBu74BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train, test, and validation split\n",
        "# Split the dataset into training (80%) and test (20%) sets\n",
        "X_main,X_test,y_main,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "# Further split the training set into training (70%) and validation (10%) sets\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_main,y_main,test_size=0.1,random_state=0)\n",
        "print(X_val.shape) # Print the shape of the validation set\n",
        "print(X_test.shape) # Print the shape of the test set\n",
        "val_rows = X_val.shape[0] # Store the number of rows in the validation set\n",
        "test_rows = X_test.shape[0] # Store the number of rows in the test set\n",
        "print(val_rows)\n",
        "print(test_rows)"
      ],
      "metadata": {
        "id": "_TKZCCKK74NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Model training with Decision Tree"
      ],
      "metadata": {
        "id": "lun_xLeI7ymS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Model training with Decision Tree\n",
        "# Create a Decision Tree Regressor with a maximum depth of 10, minimum 100 samples required to split a node, and a fixed random state for reproducibility\n",
        "regressorObject = DecisionTreeRegressor(max_depth=10,min_samples_split=100,random_state=0)\n",
        "regressorObject.fit(X_train,y_train) # Fit the model on the training data"
      ],
      "metadata": {
        "id": "1C6dhXB17y7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Predictions for test and validation sets"
      ],
      "metadata": {
        "id": "sO8sgt0e7uqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Predictions for test and validation sets\n",
        "# Predict WBGT for the test set\n",
        "y_test_pred = regressorObject.predict(X_test)\n",
        "# Predict WBGT for the validation set\n",
        "y_val_pred = regressorObject.predict(X_val)"
      ],
      "metadata": {
        "id": "RBqHEMM57u-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Performance and error metrics"
      ],
      "metadata": {
        "id": "MVPhShlt7pny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Performance and error metrics\n",
        "# Test set\n",
        "r2_test = r2_score(y_test,y_test_pred) # R2 score\n",
        "adjusted_r2_test = 1-((1-r2_test)*(test_rows-1)/(test_rows-1-colms)) # Adjusted R2 score\n",
        "print(\"R2 score: %f\"%r2_test)\n",
        "print(\"Adjusted R2 score: %f\"%adjusted_r2_test)\n",
        "print(\"MAE: %f\"%mean_absolute_error(y_test,y_test_pred))\n",
        "print(\"MAPE: %f\"%mean_absolute_percentage_error(y_test,y_test_pred))\n",
        "print(\"MSE: %f\"%mean_squared_error(y_test,y_test_pred))\n",
        "print(\"RMSE: %f\"%np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
        "# Validation set\n",
        "r2_val = r2_score(y_val,y_val_pred) # R2 score\n",
        "adjusted_r2_val = 1-((1-r2_val)*(val_rows-1)/(val_rows-1-colms)) # Adjusted R2 score\n",
        "print(\"R2 score: %f\"%r2_val)\n",
        "print(\"Adjusted R2 score: %f\"%adjusted_r2_val)\n",
        "print(\"MAE: %f\"%mean_absolute_error(y_val,y_val_pred))\n",
        "print(\"MAPE: %f\"%mean_absolute_percentage_error(y_val,y_val_pred))\n",
        "print(\"MSE: %f\"%mean_squared_error(y_val,y_val_pred))\n",
        "print(\"RMSE: %f\"%np.sqrt(mean_squared_error(y_val,y_val_pred)))"
      ],
      "metadata": {
        "id": "k9CCQxWN7p1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Customize font for plots"
      ],
      "metadata": {
        "id": "zM7XwUNG7l8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Customize font for plots\n",
        "font_upload = files.upload() # Upload custom font file\n",
        "font_path = '/content/arial.ttf' # Path to the uploaded font file\n",
        "fm.fontManager.addfont(font_path) # Add font to Matplotlib\n",
        "# Apply font customization globally\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Arial']\n",
        "plt.rcParams['font.size'] = 15"
      ],
      "metadata": {
        "id": "aVQeNnCT7mIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Scatter plot of Actual vs Predicted values"
      ],
      "metadata": {
        "id": "hd-Yl2_L7idi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Scatter plot of Actual vs Predicted values\n",
        "plt.scatter(y_test, y_test_pred, alpha=1)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test_pred), max(y_test_pred)], color='red', linewidth=2)\n",
        "plt.legend([\"Predicted\",\"Actual\"], loc=\"upper left\")\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('WBGT')"
      ],
      "metadata": {
        "id": "SXZnlMD57iuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Inference time and memory usage"
      ],
      "metadata": {
        "id": "b5RJA2M37at6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Inference time and memory usage\n",
        "# Test set\n",
        "test_initial_time = time.time()\n",
        "print(test_initial_time)\n",
        "X_test_temp_index = random.randrange(0,len(X_test)) # Choose a random row\n",
        "X_test_temp = X_test.iloc[X_test_temp_index].values.reshape(1,-1) # Reshape for prediction\n",
        "y_pred = regressorObject.predict(X_test_temp) # Perform prediction\n",
        "test_final_time = time.time()\n",
        "print(test_final_time)\n",
        "test_inference_time = test_final_time - test_initial_time # Calculate inference time\n",
        "print('Test set inference time:', test_inference_time)\n",
        "# Calculate average memory usage for prediction\n",
        "def y_pred_func():\n",
        "  return regressorObject.predict(X_test_temp)\n",
        "\n",
        "test_mem_usage = memory_usage(y_pred_func) # Track memory usage\n",
        "test_avg_mem_usage = np.mean(test_mem_usage) # Calculate average memory usage\n",
        "print('Test set avg. memory usage:', test_avg_mem_usage)\n",
        "# Validation set\n",
        "val_initial_time = time.time()\n",
        "print(val_initial_time)\n",
        "X_val_temp_index = random.randrange(0,len(X_val)) # Choose a random row\n",
        "X_val_temp = X_val.iloc[X_val_temp_index].values.reshape(1,-1) # Reshape for prediction\n",
        "y_val_pred = regressorObject.predict(X_val_temp) # Perform prediction\n",
        "val_final_time = time.time()\n",
        "print(val_final_time)\n",
        "val_inference_time = val_final_time - val_initial_time # Calculate inference time\n",
        "print('Validation set inference time:', val_inference_time)\n",
        "# Calculate average memory usage for prediction\n",
        "def y_val_pred_func():\n",
        "  return regressorObject.predict(X_val_temp)\n",
        "\n",
        "val_mem_usage = memory_usage(y_val_pred_func) # Track memory usage\n",
        "val_avg_mem_usage = np.mean(val_mem_usage) # Calculate average memory usage\n",
        "print('Validation set avg memory usage:', val_avg_mem_usage)"
      ],
      "metadata": {
        "id": "pQj2tKfM7a9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12: K-Fold cross-validation (K=10)"
      ],
      "metadata": {
        "id": "QS3Z1mCf7O7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: K-Fold cross-validation (K=10)\n",
        "k_fold = KFold(n_splits=10) # Create K-Fold cross-validator\n",
        "k_fold\n",
        "cv_score = cross_val_score(regressorObject, x,y, cv=k_fold) # Perform cross-validation\n",
        "print(\"Cross-validation scores:\", cv_score) # Print cross-validation scores"
      ],
      "metadata": {
        "id": "T023k-Rh7PNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}