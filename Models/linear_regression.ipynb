{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries\n"
      ],
      "metadata": {
        "id": "3SD5awWX2Q-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4wRqbgm1U5M"
      },
      "outputs": [],
      "source": [
        "# Linear Regression Model\n",
        "\n",
        "# Import necessary libraries for data handling, visualization, and model evaluation\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "from memory_profiler import memory_usage\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import (\n",
        "    r2_score, mean_absolute_error,\n",
        "    mean_squared_error, mean_absolute_percentage_error\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Dataset upload"
      ],
      "metadata": {
        "id": "mWwv2oXG2WxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Dataset upload\n",
        "upload = files.upload()  # Prompt the user to upload the dataset\n",
        "df = pd.read_csv('All_Div_BD.csv')  # Load dataset into a DataFrame\n",
        "dataset.shape # Print the shape of the dataset\n",
        "df.head(5) # Display the first 5 rows for preview"
      ],
      "metadata": {
        "id": "YZWTJ0o62Noc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Exclude nighttime data (hours outside 7 AM - 7 PM)"
      ],
      "metadata": {
        "id": "r77E8H5c2fx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Exclude nighttime data (hours outside 7 AM - 7 PM)\n",
        "# Filter rows with hour < 7 or hour > 19\n",
        "after_midnight_data = df[df['hour'] < 7]\n",
        "till_midnight_data = df[df['hour'] > 19]\n",
        "df = df.drop(after_midnight_data.index, axis=0)  # Drop early morning rows\n",
        "df = df.drop(till_midnight_data.index, axis=0)  # Drop late evening rows"
      ],
      "metadata": {
        "id": "xoLjeCcP2Ll1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Shuffle the dataset"
      ],
      "metadata": {
        "id": "FRT0XjFF2khd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Shuffle the dataset\n",
        "df = df.sample(frac=1, random_state=42) # Shuffle data for randomness"
      ],
      "metadata": {
        "id": "bXS56_mq2J1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Correlation matrix visualization"
      ],
      "metadata": {
        "id": "DpjLbU-p2qkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Correlation matrix visualization\n",
        "# Analyze correlations between features\n",
        "cor_matrix = df.corr()\n",
        "features = cor_matrix.index # Extract feature names\n",
        "font_upload = files.upload() # Upload custom font file\n",
        "font_path = '/content/arial.ttf' # Path to the uploaded font file\n",
        "fm.fontManager.addfont(font_path) # Add font to Matplotlib\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Arial']\n",
        "plt.rcParams['font.size'] = 15\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(df[features].corr(), annot=True)  # Generate heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TNrNmaVf2H7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define dependent (target) and independent (features) variables"
      ],
      "metadata": {
        "id": "omYNr0L-2t6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define dependent (target) and independent (features) variables\n",
        "# Exclude irrelevant columns from the feature set\n",
        "x = df.drop(['year', 'month', 'day', 'hour', 'wbgt'], axis=1).values\n",
        "y = df['wbgt'].values  # Target variable\n",
        "print(x.shape)  # Print the shape of the independent variables\n",
        "colms = x.shape[1]  # Extract the number of features (columns)\n",
        "print(colms)  # Output the number of features"
      ],
      "metadata": {
        "id": "3b7S3L4s2Cut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Train, test, and validation split"
      ],
      "metadata": {
        "id": "zXRvWW4_2yjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train, test, and validation split\n",
        "# Split the dataset into training (80%) and test (20%) sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "# Further split the training set into training (70%) and validation (10%) sets\n",
        "x_train_temp, x_val, y_train_temp, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.1, random_state=0\n",
        ")\n",
        "print(x_val.shape)  # Print the shape of the validation set\n",
        "print(x_test.shape)  # Print the shape of the test set\n",
        "val_rows = x_val.shape[0]  # Store the number of rows in the validation set\n",
        "test_rows = x_test.shape[0]  # Store the number of rows in the test set\n",
        "print(val_rows)\n",
        "print(test_rows)"
      ],
      "metadata": {
        "id": "vyHpBXKc2Ax9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Model training with Linear Regression"
      ],
      "metadata": {
        "id": "kUhjUtBV2z78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Model training with Linear Regression\n",
        "reg = LinearRegression()  # Create a Linear Regression model\n",
        "reg.fit(x_train_temp, y_train_temp)  # Fit the model on the training data"
      ],
      "metadata": {
        "id": "k2hKnwvv17-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Predictions for test and validation sets"
      ],
      "metadata": {
        "id": "r15oqr2U22N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Predictions for test and validation sets\n",
        "# Predict WBGT for the test set\n",
        "y_pred = reg.predict(x_test)\n",
        "# Predict WBGT for the validation set\n",
        "y_val_pred = reg.predict(x_val)"
      ],
      "metadata": {
        "id": "6uvHwc_61d6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Performance and error metrics"
      ],
      "metadata": {
        "id": "db4zrcqw24Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Performance and error metrics\n",
        "# Test set\n",
        "r2_test = r2_score(y_test, y_pred)  # R2 score\n",
        "adjusted_r2_test = 1 - ((1 - r2_test) * (test_rows - 1) / (test_rows - 1 - colms))  # Adjusted R2 score\n",
        "print(\"R2 score: %f\" % r2_test)\n",
        "print(\"Adjusted R2 score: %f\" % adjusted_r2_test)\n",
        "print(\"MAE: %f\" % mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE: %f\" % mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: %f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "# Validation set\n",
        "r2_val = r2_score(y_val, y_val_pred)  # R2 score\n",
        "adjusted_r2_val = 1 - ((1 - r2_val) * (val_rows - 1) / (val_rows - 1 - colms))  # Adjusted R2 score\n",
        "print(\"R2 score: %f\" % r2_val)\n",
        "print(\"Adjusted R2 score: %f\" % adjusted_r2_val)\n",
        "print(\"MAE: %f\" % mean_absolute_error(y_val, y_val_pred))\n",
        "print(\"MSE: %f\" % mean_squared_error(y_val, y_val_pred))\n",
        "print(\"RMSE: %f\" % np.sqrt(mean_squared_error(y_val, y_val_pred)))"
      ],
      "metadata": {
        "id": "Ghm2KAhO1bhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Scatter plot of Actual vs Predicted values"
      ],
      "metadata": {
        "id": "YoY-bLo027TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Scatter plot of Actual vs Predicted values\n",
        "plt.scatter(y_test, y_pred, alpha=1)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_pred), max(y_pred)], color='red', linewidth=2)  # Line of equality\n",
        "plt.legend([\"Predicted\", \"Actual\"], loc=\"upper left\")\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('WBGT')"
      ],
      "metadata": {
        "id": "ogE9ewye1bXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Inference time and memory usage"
      ],
      "metadata": {
        "id": "GIOpHIJ72_Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Inference time and memory usage\n",
        "# Test set\n",
        "test_initial_time = time.time()\n",
        "x_test_temp_index = random.randrange(0, len(x_test))  # Choose a random row\n",
        "x_test_temp = x_test[x_test_temp_index].reshape(1, -1)  # Reshape for prediction\n",
        "y_pred = reg.predict(x_test_temp)  # Perform prediction\n",
        "test_final_time = time.time()\n",
        "test_inference_time = test_final_time - test_initial_time  # Calculate inference time\n",
        "print('Test set inference time:', test_inference_time)\n",
        "# Calculate average memory usage for prediction\n",
        "def y_pred_func():\n",
        "    return reg.predict(x_test_temp)\n",
        "\n",
        "test_mem_usage = memory_usage(y_pred_func)  # Track memory usage\n",
        "test_avg_mem_usage = np.mean(test_mem_usage)  # Calculate average memory usage\n",
        "print('Test set avg. memory usage:', test_avg_mem_usage)\n",
        "# Validation set\n",
        "val_initial_time = time.time()\n",
        "x_val_temp_index = random.randrange(0, len(x_val))  # Choose a random row\n",
        "x_val_temp = x_val[x_val_temp_index].reshape(1, -1)  # Reshape for prediction\n",
        "y_val_pred = reg.predict(x_val_temp)  # Perform prediction\n",
        "val_final_time = time.time()\n",
        "val_inference_time = val_final_time - val_initial_time  # Calculate inference time\n",
        "print('Validation set inference time:', val_inference_time)\n",
        "# Calculate average memory usage for prediction\n",
        "def y_val_pred_func():\n",
        "    return reg.predict(x_val_temp)\n",
        "\n",
        "val_mem_usage = memory_usage(y_val_pred_func)  # Track memory usage\n",
        "val_avg_mem_usage = np.mean(val_mem_usage)  # Calculate average memory usage\n",
        "print('Validation set avg memory usage:', val_avg_mem_usage)"
      ],
      "metadata": {
        "id": "v-eqcrcD28s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 12: K-Fold cross-validation (K=10)"
      ],
      "metadata": {
        "id": "e9eUXQ4S3BOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: K-Fold cross-validation (K=10)\n",
        "kf = KFold(n_splits=10)  # Create K-Fold cross-validator\n",
        "cv_score = cross_val_score(LinearRegression(), x_train, y_train, cv=kf)  # Perform cross-validation\n",
        "print(\"Cross-validation scores:\", cv_score) # Print cross-validation scores"
      ],
      "metadata": {
        "id": "W9RCmB-f1bTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}